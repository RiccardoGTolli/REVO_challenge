{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import arff\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata \n",
    "dimension=pd.read_csv('dimension/dimension.csv',delimiter=';')\n",
    "sector=pd.read_csv('dimension/sector_dimension.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the .arff file:\n",
    "# Step 1: Clean random letters appearing and convert them to m\n",
    "# Step 2: Clean the letter m in the Sector column which should be numeric,\n",
    "# we know it`s the last column, convert m to ?\n",
    "# which is the null value for numeric attributes in .arff files\n",
    "# Step 3: Remove rows where the country Italy appears inb the first column\n",
    "\n",
    "for filename in os.listdir('data/'):# Loop through each file in the directory\n",
    "    with open(f'data/{filename}', 'r') as rf: # Open the .arff file\n",
    "        # Read lines from the file\n",
    "        lines = rf.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        \n",
    "        # Step 1: \n",
    "        # Clean random letters appearing and convert them to m\n",
    "        pattern = r',([a-z]),'# Regex to match comma + single lowercase letter + comma\n",
    "        # Perform the substitution\n",
    "        lines[i] = re.sub(pattern, lambda x: ',m,', line)\n",
    "        \n",
    "        # Step 2:\n",
    "        # If there is an m in the last three characters\n",
    "        if 'm' in line[-3:]:\n",
    "            # If yes, replace 'm' with '?' in the last 3 characters\n",
    "            lines[i] = line[:-3] + line[-3:].replace('m', '?')\n",
    "    \n",
    "        # Step 3:\n",
    "        # Split the string by commas\n",
    "        string_elements = line.split(',')\n",
    "        # Get the first value\n",
    "        first_value = string_elements[0]\n",
    "\n",
    "        # Check if the first value is Italy\n",
    "        if first_value == 'Italy':\n",
    "            # If not, mark the line with 'Remove'\n",
    "            lines[i] = 'Remove'\n",
    "            \n",
    "    # Let`s remove all the lines=='Remove'\n",
    "    lines = [line for line in lines if line != 'Remove']     \n",
    "    \n",
    "    # Write modified lines back to a new ARFF file\n",
    "    with open(f'data_modified/{filename}', 'w') as wf:\n",
    "        wf.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import financial data\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs_list = []\n",
    "\n",
    "for filename in os.listdir('data_modified/'):# Loop through each file in the directory\n",
    "    with open(f'data_modified/{filename}', 'r') as f: # Open the .arff file\n",
    "    \n",
    "        raw_data = arff.load(f) # dict obj\n",
    "        # Store arff in a pandas df\n",
    "        df = pd.DataFrame(raw_data['data'],columns=[x[0] for x in raw_data['attributes']])\n",
    "        \n",
    "        # Create a dict with the mappings\n",
    "        mappings = dict(zip(dimension['Variable Name'], dimension['Description']))\n",
    "        # Rename columns in df using the mapping\n",
    "        df.rename(columns=mappings,inplace=True)\n",
    "\n",
    "        # Store year and quarter cols\n",
    "        df['Year'] = int(filename[:4])\n",
    "        df['Quarter'] = filename[5:7]\n",
    "        \n",
    "        # Append DataFrame to the list\n",
    "        dfs_list.append(df)\n",
    "        \n",
    "# Concatenate all DataFrames in the list\n",
    "final_df = pd.concat(dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sector mapping in\n",
    "final_df=final_df.merge(sector,how='left', left_on='sectors', right_on='code_sector').drop(['sectors'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "final_df.replace('m', None, inplace=True)\n",
    "# Remove rows where more than threshold percent of cols are null\n",
    "threshold = int(0.7 * len(final_df.columns))\n",
    "final_df=final_df.dropna(thresh=threshold).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part from 'Quarter' column and convert to float\n",
    "final_df['Quarter'] = final_df['Quarter'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Sort df by year and quarter\n",
    "final_df=final_df.sort_values(['Year','Quarter'])\n",
    "\n",
    "# Convert numeric cols to float\n",
    "final_df = pd.concat([final_df[['Country','description_sector']], \n",
    "                final_df.drop(['Country','description_sector'],\n",
    "                        axis=1).astype(float)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Quarter to preserve its cyclic nature (useful for ml tasks)\n",
    "\n",
    "# Define the period for the trigonometric encoding (4 for quarters in a year)\n",
    "period = 4\n",
    "# Apply trigonometric coding\n",
    "final_df['sin_quarter'] = np.sin(2 * np.pi * final_df['Quarter'] / period)\n",
    "final_df['cos_quarter'] = np.cos(2 * np.pi * final_df['Quarter'] / period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df for task 1\n",
    "\n",
    "# I dont know if this makes financial sense but I will remove massive outliers because they seem off\n",
    "def remove_outliers_iqr(df,threshold):\n",
    "    \"\"\"\n",
    "    Remove outliers from each column of a DataFrame using the Interquartile Range (IQR) method.\n",
    "    \"\"\"\n",
    "    df_no_outliers = df.copy()  # Create a copy of the DataFrame to avoid modifying the original\n",
    "    \n",
    "    # Select columns with float dtype\n",
    "    float_cols = df.select_dtypes(include=['float']).columns\n",
    "\n",
    "    # Iterate over each float column\n",
    "    for column in df[float_cols].columns:\n",
    "        # Calculate the first quartile (Q1) and third quartile (Q3) for the column\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        \n",
    "        # Calculate the IQR for the column\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define the lower and upper bounds for outliers for the column\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        # Replace outliers with None for the column\n",
    "        df_no_outliers[column] = df[column].mask((df[column] < lower_bound) | (df[column] > upper_bound), other=None)\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "df_task1 = remove_outliers_iqr(final_df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute missing data with interpolation as it is time series data\n",
    "\n",
    "# Select columns with float dtype\n",
    "float_cols = df_task1.select_dtypes(include=['float']).columns\n",
    "\n",
    "# Interpolate only the float columns\n",
    "df_task1[float_cols] = df_task1[float_cols].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute the remaining missing values (due to missing from the start or from the end of df)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_task1[float_cols] = imputer.fit_transform(df_task1[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we are going to use linear regression, let s normalize the data\n",
    "scaler = StandardScaler()\n",
    "financial_cols=df_task1.drop(['Country', 'description_sector','Year', 'Quarter',\n",
    "       'code_sector', 'sin_quarter', 'cos_quarter'],axis=1).columns\t\n",
    "\n",
    "# Normalize\n",
    "df_task1[financial_cols] = scaler.fit_transform(df_task1[financial_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_task1\n",
    "df_task1.to_csv('output/df_task1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
