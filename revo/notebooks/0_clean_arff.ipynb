{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arff\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust pandas display options to show all values\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metadata \n",
    "dimension=pd.read_csv('dimension/dimension.csv',delimiter=';')\n",
    "sector=pd.read_csv('dimension/sector_dimension.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the .arff file:\n",
    "# Step 1: Clean random letters appearing and convert them to m\n",
    "# Step 2: Clean the letter m in the Sector column which should be numeric,\n",
    "# we know it`s the last column, convert m to ?\n",
    "# which is the null value for numeric attributes in .arff files\n",
    "# Step 3: Remove rows where the country Italy appears inb the first column\n",
    "\n",
    "for filename in os.listdir('data/'):# Loop through each file in the directory\n",
    "    with open(f'data/{filename}', 'r') as rf: # Open the .arff file\n",
    "        # Read lines from the file\n",
    "        lines = rf.readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        \n",
    "        # Step 1: \n",
    "        # Clean random letters appearing and convert them to m\n",
    "        pattern = r',([a-z]),'# Regex to match comma + single lowercase letter + comma\n",
    "        # Perform the substitution\n",
    "        lines[i] = re.sub(pattern, lambda x: ',m,', line)\n",
    "        \n",
    "        # Step 2:\n",
    "        # If there is an m in the last three characters\n",
    "        if 'm' in line[-3:]:\n",
    "            # If yes, replace 'm' with '?' in the last 3 characters\n",
    "            lines[i] = line[:-3] + line[-3:].replace('m', '?')\n",
    "    \n",
    "        # Step 3:\n",
    "        # Split the string by commas\n",
    "        string_elements = line.split(',')\n",
    "        # Get the first value\n",
    "        first_value = string_elements[0]\n",
    "\n",
    "        # Check if the first value is Italy\n",
    "        if first_value == 'Italy':\n",
    "            # If not, mark the line with 'Remove'\n",
    "            lines[i] = 'Remove'\n",
    "            \n",
    "    # Let`s remove all the lines=='Remove'\n",
    "    lines = [line for line in lines if line != 'Remove']     \n",
    "    \n",
    "    # Write modified lines back to a new ARFF file\n",
    "    with open(f'data_modified/{filename}', 'w') as wf:\n",
    "        wf.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the cleaned up arff files from data_modified and puts them in a single df.\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs_list = []\n",
    "\n",
    "for filename in os.listdir('data_modified/'):# Loop through each file in the directory\n",
    "    with open(f'data_modified/{filename}', 'r') as f: # Open the .arff file\n",
    "    \n",
    "        raw_data = arff.load(f) # dict obj\n",
    "        # Store arff in a pandas df\n",
    "        df = pd.DataFrame(raw_data['data'],columns=[x[0] for x in raw_data['attributes']])\n",
    "        \n",
    "        # Create a dict with the mappings\n",
    "        mappings = dict(zip(dimension['Variable Name'], dimension['Description']))\n",
    "        # Rename columns in df using the mapping\n",
    "        df.rename(columns=mappings,inplace=True)\n",
    "\n",
    "        # Store year and quarter cols\n",
    "        df['Year'] = int(filename[:4])\n",
    "        df['Quarter'] = filename[5:7]\n",
    "        \n",
    "        # Append DataFrame to the list\n",
    "        dfs_list.append(df)\n",
    "        \n",
    "# Concatenate all DataFrames in the list\n",
    "df = pd.concat(dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df.replace('m', None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no county\n",
    "df=df.dropna(subset=['Country']).reset_index(drop=True)\n",
    "# Remove rows with no sector\n",
    "df=df.dropna(subset=['sectors']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert financial indicator cols into floats\n",
    "cols=df.drop(['Country','Year','Quarter','sectors'],axis=1).columns\n",
    "df[cols] = df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where more than threshold percent of cols are null\n",
    "threshold = int(0.7 * len(df.columns))\n",
    "df=df.dropna(thresh=threshold).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values for each column:\n",
      "Country                                                                                                           0.000000\n",
      "Net profit/total assets                                                                                           0.000000\n",
      "Total liabilities/total assets                                                                                    0.000000\n",
      "Working capital/total assets                                                                                      0.190311\n",
      "Current assets/short-term liabilities                                                                             0.501730\n",
      "                                                                                                                   ...    \n",
      "Net cash flow from (used in) operating activities (n)/Net cash flow from (used in) operating activities (n−1)    39.792388\n",
      "Net cash flow(n)/net cash flow (n−1)                                                                             33.529412\n",
      "sectors                                                                                                           0.000000\n",
      "Year                                                                                                              0.000000\n",
      "Quarter                                                                                                           0.000000\n",
      "Length: 86, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of NaN values for each column\n",
    "nan_percentage = (df.isna().mean() * 100)\n",
    "# Display the percentage of NaN values for each column\n",
    "print(\"Percentage of NaN values for each column:\")\n",
    "print(nan_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sector mapping in, we choose inner to get rid of a sector=0 row\n",
    "df=df.merge(sector,how='inner', left_on='sectors', right_on='code_sector').drop(['sectors'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric part from 'Quarter' column and convert to float\n",
    "df['Quarter'] = df['Quarter'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Sort df by year and quarter\n",
    "df=df.sort_values(['Year','Quarter'])\n",
    "\n",
    "# Convert numeric cols to float\n",
    "df = pd.concat([df[['Country','description_sector']], \n",
    "                df.drop(['Country','description_sector'],\n",
    "                        axis=1).astype(float)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Quarter to preserve its cyclic nature (useful for ml tasks)\n",
    "\n",
    "# Define the period for the trigonometric encoding (4 for quarters in a year)\n",
    "period = 4\n",
    "# Apply trigonometric coding\n",
    "df['sin_quarter'] = np.sin(2 * np.pi * df['Quarter'] / period)\n",
    "df['cos_quarter'] = np.cos(2 * np.pi * df['Quarter'] / period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing indicator columns\n",
    "for col in cols:\n",
    "    missing_indicator_col_name = 'MI_'+col\n",
    "    df[missing_indicator_col_name] = df[col].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent leakage, we will output the data for task2 before any outlier and \n",
    "# missing data inputing technique\n",
    "df.to_csv('output/0_clean_arff/df_task2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing for task1 data\n",
    "# I dont know if this makes financial sense but ,I will remove massive outliers because they seem off\n",
    "def remove_outliers_iqr(df,IQR_multiplier):\n",
    "    \"\"\"\n",
    "    Remove outliers from each column of a DataFrame using the Interquartile Range (IQR) method.\n",
    "    Turns the outliers to None.\n",
    "    Smaller values of IQR_multiplier will remove outliers closer to the mean,\n",
    "    larger values of IQR_multiplier will only remove outliers farther from the mean.\n",
    "    A general rule of thumb is IQR_multiplier=1.5\n",
    "    \"\"\"\n",
    "    df_no_outliers = df.copy()  # Create a copy of the DataFrame to avoid modifying the original\n",
    "    \n",
    "    # Select columns with float dtype\n",
    "    float_cols = df.select_dtypes(include=['float']).columns\n",
    "\n",
    "    # Iterate over each float column\n",
    "    for column in df[float_cols].columns:\n",
    "        # Calculate the first quartile (Q1) and third quartile (Q3) for the column\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        \n",
    "        # Calculate the IQR for the column\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define the lower and upper bounds for outliers for the column\n",
    "        lower_bound = Q1 - IQR_multiplier * IQR\n",
    "        upper_bound = Q3 + IQR_multiplier * IQR\n",
    "        \n",
    "        # Replace outliers with None for the column\n",
    "        df_no_outliers[column] = df[column].mask((df[column] < lower_bound) | (df[column] > upper_bound), other=None)\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "df = remove_outliers_iqr(df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy() # Defragment dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['Year','Quarter']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute missing data with interpolation as it is time series data\n",
    "df[cols] = df[cols].interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpute the remaining missing values (due to missing from the start or from the end of df)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[cols] = imputer.fit_transform(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we are going to use linear regression, let s normalize the data\n",
    "scaler = StandardScaler()\n",
    "# Normalize\n",
    "df[cols] = scaler.fit_transform(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df_task1\n",
    "df.to_csv('output/0_clean_arff/df_task1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
